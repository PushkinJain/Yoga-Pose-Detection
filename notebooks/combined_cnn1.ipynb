{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e2aef-fba1-46c6-911e-5874bbe2c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e5d67-68d4-4f3a-a26b-8201101d79f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow.keras\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.applications import VGG16, InceptionResNetV2\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a91a49-d3b7-44f1-ad09-e881d9ba2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths for the two datasets\n",
    "dataset_200_path = '/kaggle/input/yoga-pose-classification/YogaPoses'\n",
    "dataset_100_path = '/kaggle/input/yoga-poses-dataset/DATASET'\n",
    "\n",
    "# Final combined folder path\n",
    "combined_dataset_path = '/kaggle/working/combined_dataset'\n",
    "\n",
    "# Pose folder names (standardized to lowercase)\n",
    "pose_folders = ['downdog', 'goddess', 'plank', 'tree', 'warrior2']\n",
    "\n",
    "# Create the combined dataset folder with 5 subfolders (one for each pose)\n",
    "if not os.path.exists(combined_dataset_path):\n",
    "    os.makedirs(combined_dataset_path)\n",
    "\n",
    "for pose in pose_folders:\n",
    "    pose_folder = os.path.join(combined_dataset_path, pose)\n",
    "    if not os.path.exists(pose_folder):\n",
    "        os.makedirs(pose_folder)\n",
    "\n",
    "# Function to copy images from a dataset folder to the combined dataset\n",
    "def copy_images(dataset_path, combined_dataset_path, pose_folders):\n",
    "    for pose_folder in pose_folders:\n",
    "        # Handle both upper and lower case folder names\n",
    "        src_folder_200 = os.path.join(dataset_path, pose_folder.capitalize())\n",
    "        src_folder_100 = os.path.join(dataset_path, pose_folder.lower())\n",
    "\n",
    "        # Check if the folder exists and copy files from it\n",
    "        if os.path.exists(src_folder_200):\n",
    "            for filename in os.listdir(src_folder_200):\n",
    "                src_file = os.path.join(src_folder_200, filename)\n",
    "                dst_file = os.path.join(combined_dataset_path, pose_folder, filename)\n",
    "                shutil.copy(src_file, dst_file)\n",
    "        elif os.path.exists(src_folder_100):\n",
    "            for filename in os.listdir(src_folder_100):\n",
    "                src_file = os.path.join(src_folder_100, filename)\n",
    "                dst_file = os.path.join(combined_dataset_path, pose_folder, filename)\n",
    "                shutil.copy(src_file, dst_file)\n",
    "\n",
    "# Copy images from Dataset_200\n",
    "copy_images(dataset_200_path, combined_dataset_path, pose_folders)\n",
    "\n",
    "# Copy images from Dataset_100 (inside 'train' and 'test' folders)\n",
    "copy_images(os.path.join(dataset_100_path, 'TRAIN'), combined_dataset_path, pose_folders)\n",
    "copy_images(os.path.join(dataset_100_path, 'TEST'), combined_dataset_path, pose_folders)\n",
    "\n",
    "print(\"Images from both datasets combined into 5 pose subfolders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5cc9d1-f35c-4dd1-b5d8-5e7926d014f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Pose.\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils  # Utility to draw landmarks and connections\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "# Main input and output folder paths\n",
    "input_main_folder = '/kaggle/working/combined_dataset'\n",
    "output_main_folder = '/kaggle/working/skeleton_combined'\n",
    "\n",
    "# Create output main folder if it doesn't exist\n",
    "os.makedirs(output_main_folder, exist_ok=True)\n",
    "\n",
    "# Loop through each subfolder (pose type)\n",
    "for subfolder in os.listdir(input_main_folder):\n",
    "    input_folder = os.path.join(input_main_folder, subfolder)\n",
    "    output_folder = os.path.join(output_main_folder, subfolder)\n",
    "    \n",
    "    # Check if the subfolder is a directory (pose folder)\n",
    "    if os.path.isdir(input_folder):\n",
    "        # Create output folder for each pose if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Process each image in the input folder\n",
    "        for filename in os.listdir(input_folder):\n",
    "            if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                # Read the image\n",
    "                image_path = os.path.join(input_folder, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                image_height, image_width, _ = image.shape\n",
    "\n",
    "                # Convert the image to RGB\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Process the image and find the pose\n",
    "                result = pose.process(image_rgb)\n",
    "\n",
    "                # Create a blank numpy array with zeros\n",
    "                skeleton_image = np.zeros((image_height, image_width, 3), dtype=np.uint8)\n",
    "\n",
    "                # Draw the skeleton on the blank image\n",
    "                if result.pose_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        skeleton_image, \n",
    "                        result.pose_landmarks, \n",
    "                        mp_pose.POSE_CONNECTIONS,  # This connects the keypoints to form the skeleton\n",
    "                        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=5, circle_radius=5),\n",
    "                        connection_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2)\n",
    "                    )\n",
    "\n",
    "                # Save the image with the skeleton\n",
    "                output_path = os.path.join(output_folder, filename)\n",
    "                cv2.imwrite(output_path, skeleton_image)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee1691-8f22-4897-bece-8835b22269f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split test train combined data\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "def split_data(src_dir, dst_dir, train_ratio=0.8):\n",
    "    # Ensure destination directories exist\n",
    "    os.makedirs(os.path.join(dst_dir, 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dst_dir, 'test'), exist_ok=True)\n",
    "    \n",
    "    # List of pose folders\n",
    "    pose_folders = ['downdog', 'goddess', 'plank', 'tree', 'warrior2']\n",
    "    \n",
    "    for pose in pose_folders:\n",
    "        # Paths\n",
    "        src_pose_dir = os.path.join(src_dir, pose)\n",
    "        train_pose_dir = os.path.join(dst_dir, 'train', pose)\n",
    "        test_pose_dir = os.path.join(dst_dir, 'test', pose)\n",
    "        \n",
    "        # Create subdirectories for train and test\n",
    "        os.makedirs(train_pose_dir, exist_ok=True)\n",
    "        os.makedirs(test_pose_dir, exist_ok=True)\n",
    "        \n",
    "        # Get all images in the pose directory\n",
    "        all_images = os.listdir(src_pose_dir)\n",
    "        \n",
    "        # Shuffle the images\n",
    "        np.random.shuffle(all_images)\n",
    "        \n",
    "        # Split indices\n",
    "        split_idx = int(len(all_images) * train_ratio)\n",
    "        \n",
    "        # Split images into train and test\n",
    "        train_images = all_images[:split_idx]\n",
    "        test_images = all_images[split_idx:]\n",
    "        \n",
    "        # Move images to respective directories\n",
    "        for img in train_images:\n",
    "            shutil.move(os.path.join(src_pose_dir, img), os.path.join(train_pose_dir, img))\n",
    "        for img in test_images:\n",
    "            shutil.move(os.path.join(src_pose_dir, img), os.path.join(test_pose_dir, img))\n",
    "\n",
    "# Define source and destination directories\n",
    "src_directory = '/kaggle/working/skeleton_combined'\n",
    "dst_directory = '/kaggle/working/split_data'\n",
    "\n",
    "# Perform the split\n",
    "split_data(src_directory, dst_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2501d2e-25bb-415d-b87e-ebf94a9af6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/kaggle/working/split_data/train' #directory with training images\n",
    "test_dir = '/kaggle/working/split_data/test' #directory with testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99212e51-10a4-452d-95d9-b469e955cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to the training data\n",
    "train_dir = '/kaggle/working/split_data/train'\n",
    "\n",
    "# List all the class subfolders\n",
    "class_names = os.listdir(train_dir)\n",
    "\n",
    "# Initialize a list to store the labels (class indices) of all images\n",
    "train_labels = []\n",
    "\n",
    "# Go through each class folder and count the images\n",
    "for class_index, class_name in enumerate(class_names):\n",
    "    class_path = os.path.join(train_dir, class_name)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    # Append the class index `num_images` times to the train_labels list\n",
    "    train_labels.extend([class_index] * num_images)\n",
    "\n",
    "# Now `train_labels` contains the class indices of all images in the training set\n",
    "# Compute the class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),  # The unique class labels\n",
    "    y=train_labels  # The list of labels\n",
    ")\n",
    "\n",
    "# Convert the class weights to a dictionary\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(class_weights_dict)  # Example: {0: 0.8, 1: 1.2, 2: 0.5, 3: 1.1, 4: 1.4}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c5ed08-5e30-473b-a218-e620f4fca915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Enhanced data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,            # Use 20% of data for validation\n",
    "    width_shift_range=0.1,            # Randomly shift images horizontally\n",
    "    height_shift_range=0.1,           # Randomly shift images vertically\n",
    "    horizontal_flip=True,             # Randomly flip images horizontally\n",
    "    rotation_range=15,                # Randomly rotate images in the range (degrees)\n",
    "    zoom_range=0.1,                   # Randomly zoom in on images\n",
    "    shear_range=0.1,                  # Randomly apply shearing transformations\n",
    "    brightness_range=[0.8, 1.2],     # Randomly adjust brightness\n",
    "    fill_mode='nearest'               # Fill mode for newly created pixels\n",
    ")\n",
    "\n",
    "# Data augmentation for testing is not needed, so just rescaling\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# Create training and validation generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(75, 75),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=16,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dir,  # This should be the same as train_dir since validation is from training data\n",
    "    target_size=(75, 75),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=16,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Create test generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(75, 75),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf393d3d-0d57-44b2-8995-c860e366b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding = 'Same', input_shape=(75, 75, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    # tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\n",
    "    # tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # tf.keras.layers.Dropout(0.25),\n",
    "    # tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\n",
    "    # tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',padding = 'Same'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405f25ad-ebf8-421f-b693-1e4583507236",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = optimizer,\n",
    "              metrics=['accuracy'])\n",
    "epochs = 100 \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f4989-ca81-40a3-9d7b-53b0ec4e2095",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f08a96c-4c91-4ed7-b080-56a9cb59323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b489453-28ab-4b07-90d2-3909d98e6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Define the checkpoint callback to save the model's weights\n",
    "checkpoint = ModelCheckpoint('model_checkpoint.weights.h5', monitor='val_loss', save_best_only=False, save_weights_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model with the checkpoint callback\n",
    "history = model.fit(train_generator, \n",
    "                    epochs=epochs, \n",
    "                    validation_data=validation_generator, \n",
    "                    callbacks=[checkpoint,early_stopping,lr_scheduler],\n",
    "                    class_weight=class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf75ff1-bdb4-4cc3-ade7-a56cf982d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model's weights from the checkpoint\n",
    "model.load_weights('model_checkpoint.weights.h5')\n",
    "# Save the entire model\n",
    "model.save('combined_cnn.keras')  # Save the complete model\n",
    "\n",
    "# Continue training from the last saved checkpoint\n",
    "# history = model.fit(train_generator, \n",
    "#                     epochs=epochs, \n",
    "#                     validation_data=validation_generator, \n",
    "#                     callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee27f4cd-cd8a-4554-9bb6-95512c9dbac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "fig.set_size_inches(12,4)\n",
    "\n",
    "ax[0].plot(history.history['accuracy'])\n",
    "ax[0].plot(history.history['val_accuracy'])\n",
    "ax[0].set_title('Training Accuracy vs Validation Accuracy')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "ax[1].plot(history.history['loss'])\n",
    "ax[1].plot(history.history['val_loss'])\n",
    "ax[1].set_title('Training Loss vs Validation Loss')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3085686d-570e-419d-8a79-b64d3fd49133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Directory containing the test folders\n",
    "# test_dir = '/kaggle/working/output_pic_withline/test'  # Update with your test dataset path that is skeletonised\n",
    "# pose_folders = ['downdog', 'goddess', 'plank', 'tree', 'warrior2']  # Update with your actual folder names\n",
    "\n",
    "# pose_map = {0: 'downdog', 1: 'goddess', 2: 'plank', 3: 'tree', 4: 'warrior2'}\n",
    "\n",
    "# # Initialize lists to store true labels and predictions\n",
    "# true_labels = []\n",
    "# predictions = []\n",
    "# predicted_pose_names = []\n",
    "\n",
    "# # Load and preprocess images\n",
    "# for label, folder in enumerate(pose_folders):\n",
    "#     folder_path = os.path.join(test_dir, folder)\n",
    "#     for img_name in os.listdir(folder_path):\n",
    "#         img_path = os.path.join(folder_path, img_name)\n",
    "#         img = load_img(img_path, target_size=(75, 75))  # Same size as your training images\n",
    "        \n",
    "#         # Convert the image to a numpy array and normalize it\n",
    "#         img_array = img_to_array(img)\n",
    "#         img_array = img_array / 255.0  # Rescale the image\n",
    "        \n",
    "#         # Add an additional dimension for batch size (as the model expects a batch of images)\n",
    "#         img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "#         # Predict the class of the image\n",
    "#         pred = model.predict(img_array)\n",
    "        \n",
    "#         # Get the predicted class index\n",
    "#         predicted_class_index = np.argmax(pred, axis=1)[0]\n",
    "        \n",
    "#         # Append true label and prediction\n",
    "#         true_labels.append(label)\n",
    "#         predictions.append(predicted_class_index)\n",
    "        \n",
    "#         predicted_pose_name = pose_map[predicted_class_index]\n",
    "#         predicted_pose_names.append(predicted_pose_name)\n",
    "\n",
    "# # Calculate accuracy\n",
    "# accuracy = accuracy_score(true_labels, predictions)\n",
    "# print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22975e-3d13-4216-9786-6ea5e50ce721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('/kaggle/working/cnn_landmark_model.keras')  # Update the path and filename as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908ad8ec-657d-465d-aeb4-457ea5952569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "\n",
    "# # Load the saved model\n",
    "# m1 = keras.models.load_model('/kaggle/input/cnn_landmark/tensorflow2/default/1/cnn_landmark_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88029a96-3cfd-4b28-85ae-fe282b573c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd01339-5319-4149-b6a1-e17dd1e0f9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ace1c4-a7f0-4bdb-a262-37a0302d5cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b40166-c821-4ac8-9712-510be1d87f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
