{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f6c14-6979-4fd6-8793-cff158c689ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#real time:\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "def real_time_pose_classification():\n",
    "    # Load the model\n",
    "    model = keras.models.load_model('C:\\\\Users\\\\Santosh\\\\Desktop\\\\fyp\\\\src\\\\saved_models\\\\cnn_landmark_model.keras')\n",
    "\n",
    "    # Define pose mapping\n",
    "    pose_map = {0: 'downdog', 1: 'goddess', 2: 'plank', 3: 'tree', 4: 'warrior'}\n",
    "\n",
    "    # Initialize MediaPipe Pose\n",
    "    mp_pose = mp.solutions.pose\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "    # Open the video capture\n",
    "    cap = cv2.VideoCapture(0)  # 0 for default webcam\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video capture\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert the frame to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame and find the pose\n",
    "        result = pose.process(frame_rgb)\n",
    "\n",
    "        # Create a blank numpy array with zeros\n",
    "        skeleton_image = np.zeros((frame.shape[0], frame.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "        # Draw the skeleton on the blank image\n",
    "        if result.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                skeleton_image,\n",
    "                result.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=5, circle_radius=5),\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2)\n",
    "            )\n",
    "\n",
    "        # Resize the skeleton image to the required input size\n",
    "        skeleton_image_resized = cv2.resize(skeleton_image, (75, 75))\n",
    "\n",
    "        # Convert to float and normalize\n",
    "        img_array = skeleton_image_resized.astype('float32') / 255.0\n",
    "\n",
    "        # Expand dimensions for model input\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        # Make the prediction\n",
    "        prediction = model.predict(img_array)\n",
    "        predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
    "        predicted_pose_name = pose_map[predicted_class_index]\n",
    "\n",
    "        # Display the predicted pose\n",
    "        cv2.putText(frame, f\"Predicted pose: {predicted_pose_name}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Pose Classification', frame)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Call the real_time_pose_classification function\n",
    "real_time_pose_classification()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
